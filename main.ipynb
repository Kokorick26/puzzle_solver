{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "cl_ugz3yGBp3",
        "outputId": "09601590-fcf8-4482-a978-af0f83317165"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'ARC-AGI-2'...\n",
            "remote: Enumerating objects: 1287, done.\u001b[K\n",
            "remote: Counting objects: 100% (65/65), done.\u001b[K\n",
            "remote: Compressing objects: 100% (56/56), done.\u001b[K\n",
            "remote: Total 1287 (delta 19), reused 31 (delta 9), pack-reused 1222 (from 2)\u001b[K\n",
            "Receiving objects: 100% (1287/1287), 604.85 KiB | 10.08 MiB/s, done.\n",
            "Resolving deltas: 100% (608/608), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/arcprize/ARC-AGI-2"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torch torchvision einops numpy"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "RnqSj1bnGW0k",
        "outputId": "aab9b258-9bb0-4073-d002-20293c2c3e19"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.6.0+cu124)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.11/dist-packages (0.21.0+cu124)\n",
            "Requirement already satisfied: einops in /usr/local/lib/python3.11/dist-packages (0.8.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (2.0.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.13.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2025.3.2)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.11/dist-packages (from torchvision) (11.1.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\n",
            "Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m117.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m87.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m59.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m12.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m79.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "Successfully installed nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json, random, time, datetime\n",
        "import torch, torch.nn as nn, torch.nn.functional as F, torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from einops import rearrange\n",
        "from PIL import Image, ImageDraw\n",
        "from torchvision import transforms\n"
      ],
      "metadata": {
        "id": "ZUfnuHJEGfzi"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the small JSON dataset of 3Ã—3 â†’ 9Ã—9 (we only need the 3Ã—3 inputs here)\n",
        "with open(\"pattern.json\") as f:\n",
        "    raw = json.load(f)[\"train\"]\n",
        "\n",
        "# Render 3Ã—3 grids as tiny RGB images (one channel repeated)\n",
        "def grid_to_img(grid, cell=16):\n",
        "    H,W = 3,3\n",
        "    img = Image.new(\"RGB\", (W*cell, H*cell), (0,0,0))\n",
        "    draw = ImageDraw.Draw(img)\n",
        "    cmap = [(i*36,)*3 for i in range(8)]\n",
        "    for i in range(H):\n",
        "        for j in range(W):\n",
        "            val = grid[i][j]\n",
        "            color = cmap[val] if val< len(cmap) else (255,255,255)\n",
        "            draw.rectangle([j*cell,i*cell,(j+1)*cell,(i+1)*cell], fill=color)\n",
        "    return img\n",
        "\n",
        "# Build a Dataset of inputâ€‘only images\n",
        "class InputOnly(Dataset):\n",
        "    def __init__(self, samples, transform):\n",
        "        self.imgs = [transform(grid_to_img(s[\"input\"])) for s in samples]\n",
        "    def __len__(self):    return len(self.imgs)\n",
        "    def __getitem__(self,i):\n",
        "        x = self.imgs[i]\n",
        "        return x, x  # autoâ€‘encode\n",
        "\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),  # [0,1], (3,48,48)\n",
        "])\n",
        "\n",
        "ds = InputOnly(raw, transform)\n",
        "loader = DataLoader(ds, batch_size=4, shuffle=True)\n"
      ],
      "metadata": {
        "id": "4Z9tt5l7Gm3Y"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class SlotAttention(nn.Module):\n",
        "    def __init__(self, num_slots, dim, iters=3, hidden_dim=64):\n",
        "        super().__init__()\n",
        "        self.num_slots, self.iters = num_slots, iters\n",
        "        self.scale = dim**-0.5\n",
        "        self.slots_mu    = nn.Parameter(torch.randn(1, num_slots, dim))\n",
        "        self.slots_sigma = nn.Parameter(torch.rand(1, num_slots, dim))\n",
        "        self.to_q = nn.Linear(dim, dim, bias=False)\n",
        "        self.to_k = nn.Linear(dim, dim, bias=False)\n",
        "        self.to_v = nn.Linear(dim, dim, bias=False)\n",
        "        self.gru = nn.GRUCell(dim, dim)\n",
        "        self.mlp = nn.Sequential(nn.Linear(dim, hidden_dim), nn.ReLU(), nn.Linear(hidden_dim, dim))\n",
        "        self.norm_input  = nn.LayerNorm(dim)\n",
        "        self.norm_slots  = nn.LayerNorm(dim)\n",
        "        self.norm_pre_ff = nn.LayerNorm(dim)\n",
        "\n",
        "    def forward(self, x):\n",
        "        B, N, D = x.shape\n",
        "        mu  = self.slots_mu.expand(B, -1, -1)\n",
        "        sig = F.softplus(self.slots_sigma).expand(B, -1, -1)\n",
        "        slots = mu + sig * torch.randn_like(mu)\n",
        "        x = self.norm_input(x)\n",
        "        k,v = self.to_k(x), self.to_v(x)\n",
        "\n",
        "        for _ in range(self.iters):\n",
        "            slots_prev = slots\n",
        "            slots_norm = self.norm_slots(slots)\n",
        "            q = self.to_q(slots_norm)\n",
        "            attn_logits = torch.einsum('bnd,bsd->bns', k, q)*self.scale\n",
        "            attn = attn_logits.softmax(dim=1)\n",
        "            updates = torch.einsum('bns,bnd->bsd', attn, v)\n",
        "            slots = self.gru(updates.reshape(-1,D), slots_prev.reshape(-1,D)).reshape(B, -1, D)\n",
        "            slots = slots + self.mlp(self.norm_pre_ff(slots))\n",
        "        return slots\n",
        "\n",
        "class SlotAutoEncoder(nn.Module):\n",
        "    def __init__(self, res=(48,48), hidden=64, slots=9):\n",
        "        super().__init__()\n",
        "        C=3; H,W=res\n",
        "        self.encoder = nn.Sequential(\n",
        "            nn.Conv2d(C, hidden, 5, padding=2), nn.ReLU(),\n",
        "            nn.Conv2d(hidden, hidden,5,padding=2), nn.ReLU(),\n",
        "        )\n",
        "        self.pos_emb = nn.Parameter(torch.randn(1, H*W, hidden))\n",
        "        self.slot_attn = SlotAttention(slots, hidden)\n",
        "        self.decoder = nn.Sequential(\n",
        "            nn.ConvTranspose2d(hidden, hidden,5,padding=2), nn.ReLU(),\n",
        "            nn.ConvTranspose2d(hidden, C, 5, padding=2), nn.Sigmoid()\n",
        "        )\n",
        "\n",
        "    def forward(self,x):\n",
        "        B,C,H,W = x.shape\n",
        "        f = self.encoder(x)                  # [B,hidden,H,W]\n",
        "        tokens = (f.flatten(2).permute(0,2,1) + self.pos_emb)  # [B,H*W,hidden]\n",
        "        slots = self.slot_attn(tokens)       # [B,slots,hidden]\n",
        "        # Broadcast each slot to map and decode separately\n",
        "        out = 0\n",
        "        for s in slots.permute(1,0,2):       # slots Ã— [B,hidden]\n",
        "            feat = s.unsqueeze(-1).unsqueeze(-1).expand(-1,-1,H,W)\n",
        "            out = out + self.decoder(feat)\n",
        "        return out / slots.shape[1], slots   # recon, slots\n",
        "\n",
        "# Instantiate\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = SlotAutoEncoder(res=(48,48), hidden=64, slots=9).to(device)\n",
        "opt = optim.Adam(model.parameters(), lr=3e-4)\n",
        "criterion = nn.MSELoss()\n"
      ],
      "metadata": {
        "id": "BZw8UgABHUpC"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "EPOCHS=50\n",
        "for ep in range(1, EPOCHS+1):\n",
        "    model.train(); L=0\n",
        "    for x, _ in loader:\n",
        "        x = x.to(device)\n",
        "        recon, slots = model(x)\n",
        "        loss = criterion(recon, x)\n",
        "        opt.zero_grad(); loss.backward(); opt.step()\n",
        "        L += loss.item()\n",
        "    print(f\"Ep{ep:02d} â†“ Loss {L/len(loader):.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d1uOxNNxHdhQ",
        "outputId": "3a0a565c-00d1-402d-910e-0aab5627f339"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ep01 â†“ Loss 0.1203\n",
            "Ep02 â†“ Loss 0.1148\n",
            "Ep03 â†“ Loss 0.1144\n",
            "Ep04 â†“ Loss 0.1142\n",
            "Ep05 â†“ Loss 0.1143\n",
            "Ep06 â†“ Loss 0.1142\n",
            "Ep07 â†“ Loss 0.1140\n",
            "Ep08 â†“ Loss 0.1140\n",
            "Ep09 â†“ Loss 0.1140\n",
            "Ep10 â†“ Loss 0.1140\n",
            "Ep11 â†“ Loss 0.1138\n",
            "Ep12 â†“ Loss 0.1139\n",
            "Ep13 â†“ Loss 0.1140\n",
            "Ep14 â†“ Loss 0.1138\n",
            "Ep15 â†“ Loss 0.1136\n",
            "Ep16 â†“ Loss 0.1118\n",
            "Ep17 â†“ Loss 0.1108\n",
            "Ep18 â†“ Loss 0.1092\n",
            "Ep19 â†“ Loss 0.1076\n",
            "Ep20 â†“ Loss 0.1074\n",
            "Ep21 â†“ Loss 0.1073\n",
            "Ep22 â†“ Loss 0.1070\n",
            "Ep23 â†“ Loss 0.1068\n",
            "Ep24 â†“ Loss 0.1058\n",
            "Ep25 â†“ Loss 0.1052\n",
            "Ep26 â†“ Loss 0.1051\n",
            "Ep27 â†“ Loss 0.1048\n",
            "Ep28 â†“ Loss 0.1048\n",
            "Ep29 â†“ Loss 0.1046\n",
            "Ep30 â†“ Loss 0.1047\n",
            "Ep31 â†“ Loss 0.1046\n",
            "Ep32 â†“ Loss 0.1045\n",
            "Ep33 â†“ Loss 0.1047\n",
            "Ep34 â†“ Loss 0.1045\n",
            "Ep35 â†“ Loss 0.1044\n",
            "Ep36 â†“ Loss 0.1043\n",
            "Ep37 â†“ Loss 0.1045\n",
            "Ep38 â†“ Loss 0.1043\n",
            "Ep39 â†“ Loss 0.1043\n",
            "Ep40 â†“ Loss 0.1042\n",
            "Ep41 â†“ Loss 0.1042\n",
            "Ep42 â†“ Loss 0.1042\n",
            "Ep43 â†“ Loss 0.1040\n",
            "Ep44 â†“ Loss 0.1040\n",
            "Ep45 â†“ Loss 0.1040\n",
            "Ep46 â†“ Loss 0.1038\n",
            "Ep47 â†“ Loss 0.1037\n",
            "Ep48 â†“ Loss 0.1037\n",
            "Ep49 â†“ Loss 0.1036\n",
            "Ep50 â†“ Loss 0.1035\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# pick one sample\n",
        "img, _ = ds[0]\n",
        "x = img.unsqueeze(0).to(device)  # [1,3,48,48]\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    recon, masks = model(x)\n",
        "\n",
        "# masks: [1,slots,hidden] -- we need per-slot spatial masks:\n",
        "# instead, re-decode with alpha-head removed: use attention from SlotAttention?\n",
        "# For simplicity, we'll skip to symbolic step: we know the original grid.\n",
        "\n",
        "grid3 = raw[0][\"input\"]\n"
      ],
      "metadata": {
        "id": "mVdNuyFhI3G1"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def tile_rule(input_grid):\n",
        "    out = [[0]*9 for _ in range(9)]\n",
        "    for i in range(3):\n",
        "        for j in range(3):\n",
        "            if input_grid[i][j]!=0:\n",
        "                for di in range(3):\n",
        "                    for dj in range(3):\n",
        "                        out[3*i+di][3*j+dj] = input_grid[di][dj]\n",
        "    return out\n",
        "\n",
        "pred = tile_rule(grid3)\n",
        "print(\"Predicted:\\n\", pred)\n",
        "print(\"Ground-truth:\\n\", raw[0][\"output\"])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_PgkUO4ZI8Rh",
        "outputId": "9de4f1d1-bcd4-48f7-e2a5-caf19aae36bd"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted:\n",
            " [[4, 2, 0, 4, 2, 0, 0, 0, 0], [0, 0, 2, 0, 0, 2, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 4, 2, 0], [0, 0, 0, 0, 0, 0, 0, 0, 2], [0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0]]\n",
            "Ground-truth:\n",
            " [[4, 2, 0, 4, 2, 0, 0, 0, 0], [0, 0, 2, 0, 0, 2, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 4, 2, 0], [0, 0, 0, 0, 0, 0, 0, 0, 2], [0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def tile_rule(input_grid):\n",
        "    \"\"\"\n",
        "    For each nonâ€‘zero in the 3Ã—3 input, copies the entire 3Ã—3 block\n",
        "    into the corresponding 3Ã—3 region of the 9Ã—9 output.\n",
        "    \"\"\"\n",
        "    out = [[0]*9 for _ in range(9)]\n",
        "    for i in range(3):\n",
        "        for j in range(3):\n",
        "            if input_grid[i][j] != 0:\n",
        "                for di in range(3):\n",
        "                    for dj in range(3):\n",
        "                        out[3*i+di][3*j+dj] = input_grid[di][dj]\n",
        "    return out\n"
      ],
      "metadata": {
        "id": "sKwUO-AEJxbh"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ğŸ”§ Edit this 3Ã—3 grid however you like:\n",
        "my_input = [\n",
        "    [2, 2, 2],\n",
        "    [0, 0, 0],\n",
        "    [0, 2, 2]\n",
        "]\n",
        "\n",
        "# Run the tiling rule\n",
        "predicted = tile_rule(my_input)\n",
        "\n",
        "# Print the 3Ã—3 input\n",
        "print(\"ğŸ§© Input (3Ã—3):\")\n",
        "for row in my_input:\n",
        "    print(row)\n",
        "\n",
        "# Print a separator\n",
        "print(\"\\nâ†³ Predicted 9Ã—9 output:\")\n",
        "for row in predicted:\n",
        "    print(row)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cArJDd0pJ2aD",
        "outputId": "cc94b78b-1b13-46dc-ddf5-7c5a8d912ce1"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ğŸ§© Input (3Ã—3):\n",
            "[2, 2, 2]\n",
            "[0, 0, 0]\n",
            "[0, 2, 2]\n",
            "\n",
            "â†³ Predicted 9Ã—9 output:\n",
            "[2, 2, 2, 2, 2, 2, 2, 2, 2]\n",
            "[0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "[0, 2, 2, 0, 2, 2, 0, 2, 2]\n",
            "[0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "[0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "[0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "[0, 0, 0, 2, 2, 2, 2, 2, 2]\n",
            "[0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "[0, 0, 0, 0, 2, 2, 0, 2, 2]\n"
          ]
        }
      ]
    }
  ]
}